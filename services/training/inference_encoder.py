#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„CLIP encoderè¿›è¡Œæ¨ç†
æ”¯æŒå•å¼ å›¾åƒç¼–ç å’Œæ‰¹é‡ç¼–ç 
"""
import os
import sys
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Tuple
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "services" / "training"))

from clip_contrastive_trainer import CLIPEncoder, CandlestickRenderer, KLineDataset


class TrainedEncoder:
    """è®­ç»ƒå¥½çš„ç¼–ç å™¨æ¨ç†ç±»"""
    
    def __init__(self, checkpoint_path: str, device: str = "auto"):
        """
        åŠ è½½è®­ç»ƒå¥½çš„ç¼–ç å™¨
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
            device: è®¾å¤‡ç±»å‹
        """
        # è®¾ç½®è®¾å¤‡
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        print(f"[Encoder] Using device: {self.device}")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        state = checkpoint["model_state_dict"]

        # å…¼å®¹ VICReg/Barlow/SimSiamï¼šcheckpoint å­˜çš„æ˜¯å®Œæ•´æ¨¡å‹ (encoder.xxx + projector.xxx)ï¼Œåªå– encoder éƒ¨åˆ†
        if any(k.startswith("encoder.") for k in state.keys()):
            encoder_state = {k.replace("encoder.", "", 1): v for k, v in state.items() if k.startswith("encoder.")}
            state = encoder_state
            print("[Encoder] Detected VICReg/Barlow/SimSiam checkpoint, loading encoder only")

        # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½
        self.model = CLIPEncoder(embedding_dim=512)
        self.model.load_state_dict(state, strict=True)
        self.model.to(self.device)
        self.model.eval()

        self.epoch = checkpoint.get("epoch", 0)
        self.metrics = checkpoint.get("metrics", {})
        print(f"[Encoder] Loaded encoder from epoch {self.epoch}")
        if self.metrics:
            print(f"[Encoder] Metrics: {self.metrics}")
        
        # åˆå§‹åŒ–æ¸²æŸ“å™¨
        self.renderer = CandlestickRenderer(image_size=224)
    
    def encode_image(self, image: np.ndarray) -> np.ndarray:
        """
        ç¼–ç å•å¼ å›¾åƒ
        
        Args:
            image: RGBå›¾åƒæ•°ç»„ [H, W, 3]
        
        Returns:
            åµŒå…¥å‘é‡ [embedding_dim]
        """
        # è½¬æ¢ä¸ºtensor
        if isinstance(image, np.ndarray):
            image_tensor = torch.from_numpy(image).float()
        
        # ç¡®ä¿æ˜¯CHWæ ¼å¼
        if image_tensor.dim() == 3 and image_tensor.shape[-1] == 3:
            image_tensor = image_tensor.permute(2, 0, 1)
        
        # å½’ä¸€åŒ–åˆ°[0, 1]
        if image_tensor.max() > 1.0:
            image_tensor = image_tensor / 255.0
        
        # æ·»åŠ batchç»´åº¦
        image_tensor = image_tensor.unsqueeze(0).to(self.device)
        
        # ç¼–ç 
        with torch.no_grad():
            embedding = self.model(image_tensor)
        
        return embedding.cpu().numpy().squeeze()
    
    def encode_ohlc_data(self, ohlc_data: pd.DataFrame) -> np.ndarray:
        """
        ç¼–ç OHLCæ•°æ®
        
        Args:
            ohlc_data: DataFrame with columns ['open', 'high', 'low', 'close', 'volume']
        
        Returns:
            åµŒå…¥å‘é‡ [embedding_dim]
        """
        # æ¸²æŸ“èœ¡çƒ›å›¾
        image = self.renderer.render_candlestick(ohlc_data)
        
        # ç¼–ç å›¾åƒ
        return self.encode_image(image)
    
    def encode_batch(self, images: List[np.ndarray]) -> np.ndarray:
        """
        æ‰¹é‡ç¼–ç å›¾åƒ
        
        Args:
            images: å›¾åƒåˆ—è¡¨
        
        Returns:
            åµŒå…¥çŸ©é˜µ [batch_size, embedding_dim]
        """
        embeddings = []
        
        for image in images:
            embedding = self.encode_image(image)
            embeddings.append(embedding)
        
        return np.array(embeddings)
    
    def compute_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            embedding1: ç¬¬ä¸€ä¸ªåµŒå…¥å‘é‡
            embedding2: ç¬¬äºŒä¸ªåµŒå…¥å‘é‡
        
        Returns:
            ä½™å¼¦ç›¸ä¼¼åº¦ [0, 1]
        """
        # å½’ä¸€åŒ–
        norm1 = np.linalg.norm(embedding1)
        norm2 = np.linalg.norm(embedding2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
        
        return float(similarity)
    
    def find_similar_patterns(
        self, 
        query_embedding: np.ndarray, 
        candidate_embeddings: np.ndarray,
        top_k: int = 5
    ) -> List[Tuple[int, float]]:
        """
        æ‰¾åˆ°æœ€ç›¸ä¼¼çš„Kä¸ªæ¨¡å¼
        
        Args:
            query_embedding: æŸ¥è¯¢åµŒå…¥å‘é‡
            candidate_embeddings: å€™é€‰åµŒå…¥çŸ©é˜µ [N, embedding_dim]
            top_k: è¿”å›å‰Kä¸ªæœ€ç›¸ä¼¼çš„
        
        Returns:
            ç›¸ä¼¼åº¦æ’åºåˆ—è¡¨ [(index, similarity), ...]
        """
        similarities = []
        
        for i, candidate in enumerate(candidate_embeddings):
            similarity = self.compute_similarity(query_embedding, candidate)
            similarities.append((i, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]


def demo_encoder_usage():
    """æ¼”ç¤ºç¼–ç å™¨ä½¿ç”¨æ–¹æ³•"""
    print("ğŸš€ CLIP Encoder Inference Demo")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    checkpoint_path = "services/training/logs/clip_contrastive/checkpoint_best.pth"
    if not Path(checkpoint_path).exists():
        print(f"âŒ Model checkpoint not found: {checkpoint_path}")
        return
    
    # åŠ è½½ç¼–ç å™¨
    print("ğŸ“ Loading trained encoder...")
    encoder = TrainedEncoder(checkpoint_path)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“Š Loading test data...")
    test_dataset = KLineDataset(
        data_file="services/training/data/dow30_real_AAPL.csv",
        start_year=2017,
        end_year=2017,
        window_size=5,
        step_size=3,
        image_size=224,
        mode="test"
    )
    
    print(f"ğŸ“ˆ Test dataset: {len(test_dataset)} windows")
    
    # ç¼–ç å‡ ä¸ªæµ‹è¯•æ ·æœ¬
    print("ğŸ” Encoding test samples...")
    test_embeddings = []
    
    for i in range(min(5, len(test_dataset))):
        sample = test_dataset[i]
        window_info = sample['window_info']
        
        # æ¸²æŸ“èœ¡çƒ›å›¾
        renderer = CandlestickRenderer(image_size=224)
        image = renderer.render_candlestick(test_dataset.windows[i])
        
        # ç¼–ç 
        embedding = encoder.encode_image(image)
        test_embeddings.append(embedding)
        
        print(f"  Sample {i+1}: {window_info['start_date']} to {window_info['end_date']}")
        print(f"    Price change: {window_info['price_change']:.4f}")
        print(f"    Embedding norm: {np.linalg.norm(embedding):.4f}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    print("\nğŸ”— Computing similarity matrix...")
    similarities = []
    
    for i in range(len(test_embeddings)):
        for j in range(i+1, len(test_embeddings)):
            sim = encoder.compute_similarity(test_embeddings[i], test_embeddings[j])
            similarities.append((i, j, sim))
            print(f"  Similarity between sample {i+1} and {j+1}: {sim:.4f}")
    
    # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ ·æœ¬å¯¹
    if similarities:
        best_sim = max(similarities, key=lambda x: x[2])
        print(f"\nğŸ¯ Most similar pair: samples {best_sim[0]+1} and {best_sim[1]+1}")
        print(f"   Similarity: {best_sim[2]:.4f}")
    
    print("\nâœ… Encoder inference demo completed!")
    print("\nğŸ“ Usage Summary:")
    print("1. Load encoder: encoder = TrainedEncoder('checkpoint_path')")
    print("2. Encode image: embedding = encoder.encode_image(image)")
    print("3. Encode OHLC: embedding = encoder.encode_ohlc_data(ohlc_df)")
    print("4. Compute similarity: sim = encoder.compute_similarity(emb1, emb2)")
    print("5. Find similar patterns: results = encoder.find_similar_patterns(query, candidates)")


if __name__ == "__main__":
    demo_encoder_usage()

